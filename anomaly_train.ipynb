{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZJLLdHFcjyoV+zAhXrdgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Logeshwari-2001/Anomaly/blob/main/anomaly_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zky8FcgKYdRb",
        "outputId": "82fa70ec-2f16-47d5-f7b3-107b0d0992eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas : 1.4.4\n",
            "numpy : 1.22.4\n",
            "matplotlib : 3.7.1\n",
            "seaborn : 0.12.2\n",
            "sklearn : 1.2.2\n",
            "imblearn : 0.10.1\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import imblearn\n",
        "import sys\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "np.set_printoptions(precision=3)\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "print(\"pandas : {0}\".format(pd.__version__))\n",
        "print(\"numpy : {0}\".format(np.__version__))\n",
        "print(\"matplotlib : {0}\".format(matplotlib.__version__))\n",
        "print(\"seaborn : {0}\".format(sns.__version__))\n",
        "print(\"sklearn : {0}\".format(sklearn.__version__))\n",
        "print(\"imblearn : {0}\".format(imblearn.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datacols = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"attack\", \"last_flag\"]\n",
        "\n",
        "# Load NSL_KDD train dataset\n",
        "train = pd.read_table(\"/content/KDDTrain.txt\", sep=\",\", names=datacols) # change path to where the dataset is located.\n",
        "train = train.iloc[:,:-1] # removes an unwanted extra field"
      ],
      "metadata": {
        "id": "4z0OomUgoD5m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head(4))\n",
        "\n",
        "print(\"Training data has {} rows & {} columns\".format(train.shape[0],train.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V42cq5GCoOL4",
        "outputId": "c05537b3-1894-43d2-a069-4e88b4a85040"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
            "0         0           tcp  ftp_data   SF        491          0     0   \n",
            "1         0           udp     other   SF        146          0     0   \n",
            "2         0           tcp   private   S0          0          0     0   \n",
            "3         0           tcp      http   SF        232       8153     0   \n",
            "\n",
            "   wrong_fragment  urgent  hot  num_failed_logins  logged_in  num_compromised  \\\n",
            "0               0       0    0                  0          0                0   \n",
            "1               0       0    0                  0          0                0   \n",
            "2               0       0    0                  0          0                0   \n",
            "3               0       0    0                  0          1                0   \n",
            "\n",
            "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
            "0           0             0         0                   0           0   \n",
            "1           0             0         0                   0           0   \n",
            "2           0             0         0                   0           0   \n",
            "3           0             0         0                   0           0   \n",
            "\n",
            "   num_access_files  num_outbound_cmds  is_host_login  is_guest_login  count  \\\n",
            "0                 0                  0              0               0      2   \n",
            "1                 0                  0              0               0     13   \n",
            "2                 0                  0              0               0    123   \n",
            "3                 0                  0              0               0      5   \n",
            "\n",
            "   srv_count  serror_rate  srv_serror_rate  rerror_rate  srv_rerror_rate  \\\n",
            "0          2          0.0              0.0          0.0              0.0   \n",
            "1          1          0.0              0.0          0.0              0.0   \n",
            "2          6          1.0              1.0          0.0              0.0   \n",
            "3          5          0.2              0.2          0.0              0.0   \n",
            "\n",
            "   same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
            "0           1.00           0.00                 0.0             150   \n",
            "1           0.08           0.15                 0.0             255   \n",
            "2           0.05           0.07                 0.0             255   \n",
            "3           1.00           0.00                 0.0              30   \n",
            "\n",
            "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "0                  25                    0.17                    0.03   \n",
            "1                   1                    0.00                    0.60   \n",
            "2                  26                    0.10                    0.05   \n",
            "3                 255                    1.00                    0.00   \n",
            "\n",
            "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "0                         0.17                         0.00   \n",
            "1                         0.88                         0.00   \n",
            "2                         0.00                         0.00   \n",
            "3                         0.03                         0.04   \n",
            "\n",
            "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "0                  0.00                      0.00                  0.05   \n",
            "1                  0.00                      0.00                  0.00   \n",
            "2                  1.00                      1.00                  0.00   \n",
            "3                  0.03                      0.01                  0.00   \n",
            "\n",
            "   dst_host_srv_rerror_rate   attack  \n",
            "0                      0.00   normal  \n",
            "1                      0.00   normal  \n",
            "2                      0.00  neptune  \n",
            "3                      0.01   normal  \n",
            "Training data has 125973 rows & 42 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {'ipsweep': 'Probe','satan': 'Probe','nmap': 'Probe','portsweep': 'Probe','saint': 'Probe','mscan': 'Probe',\n",
        "        'teardrop': 'DoS','pod': 'DoS','land': 'DoS','back': 'DoS','neptune': 'DoS','smurf': 'DoS','mailbomb': 'DoS',\n",
        "        'udpstorm': 'DoS','apache2': 'DoS','processtable': 'DoS',\n",
        "        'perl': 'U2R','loadmodule': 'U2R','rootkit': 'U2R','buffer_overflow': 'U2R','xterm': 'U2R','ps': 'U2R',\n",
        "        'sqlattack': 'U2R','httptunnel': 'U2R',\n",
        "        'ftp_write': 'R2L','phf': 'R2L','guess_passwd': 'R2L','warezmaster': 'R2L','warezclient': 'R2L','imap': 'R2L',\n",
        "        'spy': 'R2L','multihop': 'R2L','named': 'R2L','snmpguess': 'R2L','worm': 'R2L','snmpgetattack': 'R2L',\n",
        "        'xsnoop': 'R2L','xlock': 'R2L','sendmail': 'R2L',\n",
        "        'normal': 'Normal'\n",
        "        }"
      ],
      "metadata": {
        "id": "bY1OtljmoRFa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['attack_class'] = train['attack'].apply(lambda v: mapping[v])"
      ],
      "metadata": {
        "id": "BF86ntN0oUXf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['attack'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "hRC2qzcOoamw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Jk61544GodDk",
        "outputId": "9c83888d-7972-4b8b-cfaf-59a2cefea561"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
              "0         0           tcp  ftp_data   SF        491          0     0   \n",
              "1         0           udp     other   SF        146          0     0   \n",
              "2         0           tcp   private   S0          0          0     0   \n",
              "\n",
              "   wrong_fragment  urgent  hot  num_failed_logins  logged_in  num_compromised  \\\n",
              "0               0       0    0                  0          0                0   \n",
              "1               0       0    0                  0          0                0   \n",
              "2               0       0    0                  0          0                0   \n",
              "\n",
              "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
              "0           0             0         0                   0           0   \n",
              "1           0             0         0                   0           0   \n",
              "2           0             0         0                   0           0   \n",
              "\n",
              "   num_access_files  num_outbound_cmds  is_host_login  is_guest_login  count  \\\n",
              "0                 0                  0              0               0      2   \n",
              "1                 0                  0              0               0     13   \n",
              "2                 0                  0              0               0    123   \n",
              "\n",
              "   srv_count  serror_rate  srv_serror_rate  rerror_rate  srv_rerror_rate  \\\n",
              "0          2          0.0              0.0          0.0              0.0   \n",
              "1          1          0.0              0.0          0.0              0.0   \n",
              "2          6          1.0              1.0          0.0              0.0   \n",
              "\n",
              "   same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
              "0           1.00           0.00                 0.0             150   \n",
              "1           0.08           0.15                 0.0             255   \n",
              "2           0.05           0.07                 0.0             255   \n",
              "\n",
              "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
              "0                  25                    0.17                    0.03   \n",
              "1                   1                    0.00                    0.60   \n",
              "2                  26                    0.10                    0.05   \n",
              "\n",
              "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
              "0                         0.17                          0.0   \n",
              "1                         0.88                          0.0   \n",
              "2                         0.00                          0.0   \n",
              "\n",
              "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
              "0                   0.0                       0.0                  0.05   \n",
              "1                   0.0                       0.0                  0.00   \n",
              "2                   1.0                       1.0                  0.00   \n",
              "\n",
              "   dst_host_srv_rerror_rate attack_class  \n",
              "0                       0.0       Normal  \n",
              "1                       0.0       Normal  \n",
              "2                       0.0          DoS  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79a3f32a-4e9f-4803-be32-d003ffbee9ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>attack_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150</td>\n",
              "      <td>25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255</td>\n",
              "      <td>26</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DoS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79a3f32a-4e9f-4803-be32-d003ffbee9ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79a3f32a-4e9f-4803-be32-d003ffbee9ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79a3f32a-4e9f-4803-be32-d003ffbee9ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['num_outbound_cmds'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImuyHZiuohFa",
        "outputId": "e015ae74-3a00-4213-eb72-b2774079d967"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    125973\n",
            "Name: num_outbound_cmds, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['num_outbound_cmds'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "t51OwZoRohbX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_class_freq_train = train[['attack_class']].apply(lambda x: x.value_counts())\n",
        "#attack_class_freq_test = test[['attack_class']].apply(lambda x: x.value_counts())\n",
        "attack_class_freq_train['frequency_percent_train'] = round((100 * attack_class_freq_train / attack_class_freq_train.sum()),2)"
      ],
      "metadata": {
        "id": "JmMNGxSJoj6p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
        "cols = train.select_dtypes(include=['float64','int64']).columns\n",
        "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
        "#sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
        "\n",
        "# turn the result back to a dataframe\n",
        "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
        "#sc_testdf = pd.DataFrame(sc_test, columns = cols)"
      ],
      "metadata": {
        "id": "0RjKtEDvo0Xh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# extract categorical attributes from both training and test sets \n",
        "cattrain = train.select_dtypes(include=['object']).copy()\n",
        "#cattest = test.select_dtypes(include=['object']).copy()\n",
        "\n",
        "# encode the categorical attributes\n",
        "traincat = cattrain.apply(encoder.fit_transform)\n",
        "#testcat = cattest.apply(encoder.fit_transform)\n",
        "\n",
        "# separate target column from encoded data \n",
        "enctrain = traincat.drop(['attack_class'], axis=1)\n",
        "cat_Ytrain = traincat[['attack_class']].copy()"
      ],
      "metadata": {
        "id": "28RtOR83o60l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = pd.concat([sc_traindf,enctrain],axis=1)\n",
        "train_y = train['attack_class']\n",
        "train_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp8-hn0FpWJP",
        "outputId": "2b967809-4857-43e3-9216-30b386bbe723"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125973, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "0_j-XWespZlh",
        "outputId": "c28429dc-dbf3-46a5-c2d3-b6582448a123"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n",
              "0      -0.110249  -0.007679  -0.004919 -0.014089       -0.089486 -0.007736   \n",
              "1      -0.110249  -0.007737  -0.004919 -0.014089       -0.089486 -0.007736   \n",
              "2      -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
              "3      -0.110249  -0.007723  -0.002891 -0.014089       -0.089486 -0.007736   \n",
              "4      -0.110249  -0.007728  -0.004814 -0.014089       -0.089486 -0.007736   \n",
              "...          ...        ...        ...       ...             ...       ...   \n",
              "125968 -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
              "125969 -0.107178  -0.007744  -0.004883 -0.014089       -0.089486 -0.007736   \n",
              "125970 -0.110249  -0.007382  -0.004823 -0.014089       -0.089486 -0.007736   \n",
              "125971 -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
              "125972 -0.110249  -0.007737  -0.004919 -0.014089       -0.089486 -0.007736   \n",
              "\n",
              "             hot  num_failed_logins  logged_in  num_compromised  root_shell  \\\n",
              "0      -0.095076          -0.027023  -0.809262        -0.011664   -0.036652   \n",
              "1      -0.095076          -0.027023  -0.809262        -0.011664   -0.036652   \n",
              "2      -0.095076          -0.027023  -0.809262        -0.011664   -0.036652   \n",
              "3      -0.095076          -0.027023   1.235694        -0.011664   -0.036652   \n",
              "4      -0.095076          -0.027023   1.235694        -0.011664   -0.036652   \n",
              "...          ...                ...        ...              ...         ...   \n",
              "125968 -0.095076          -0.027023  -0.809262        -0.011664   -0.036652   \n",
              "125969 -0.095076          -0.027023  -0.809262        -0.011664   -0.036652   \n",
              "125970 -0.095076          -0.027023   1.235694        -0.011664   -0.036652   \n",
              "125971 -0.095076          -0.027023  -0.809262        -0.011664   -0.036652   \n",
              "125972 -0.095076          -0.027023   1.235694        -0.011664   -0.036652   \n",
              "\n",
              "        su_attempted  num_root  num_file_creations  num_shells  \\\n",
              "0          -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "1          -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "2          -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "3          -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "4          -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "...              ...       ...                 ...         ...   \n",
              "125968     -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "125969     -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "125970     -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "125971     -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "125972     -0.024437 -0.012385            -0.02618    -0.01861   \n",
              "\n",
              "        num_access_files  is_host_login  is_guest_login     count  srv_count  \\\n",
              "0              -0.041221      -0.002817       -0.097531 -0.717045  -0.354343   \n",
              "1              -0.041221      -0.002817       -0.097531 -0.620982  -0.368110   \n",
              "2              -0.041221      -0.002817       -0.097531  0.339648  -0.299273   \n",
              "3              -0.041221      -0.002817       -0.097531 -0.690846  -0.313041   \n",
              "4              -0.041221      -0.002817       -0.097531 -0.472521   0.058678   \n",
              "...                  ...            ...             ...       ...        ...   \n",
              "125968         -0.041221      -0.002817       -0.097531  0.872361  -0.037694   \n",
              "125969         -0.041221      -0.002817       -0.097531 -0.717045  -0.354343   \n",
              "125970         -0.041221      -0.002817       -0.097531 -0.725778  -0.368110   \n",
              "125971         -0.041221      -0.002817       -0.097531  0.523041  -0.271739   \n",
              "125972         -0.041221      -0.002817       -0.097531 -0.725778  -0.368110   \n",
              "\n",
              "        serror_rate  srv_serror_rate  rerror_rate  srv_rerror_rate  \\\n",
              "0         -0.637209        -0.631929    -0.374362        -0.374432   \n",
              "1         -0.637209        -0.631929    -0.374362        -0.374432   \n",
              "2          1.602664         1.605104    -0.374362        -0.374432   \n",
              "3         -0.189235        -0.184522    -0.374362        -0.374432   \n",
              "4         -0.637209        -0.631929    -0.374362        -0.374432   \n",
              "...             ...              ...          ...              ...   \n",
              "125968     1.602664         1.605104    -0.374362        -0.374432   \n",
              "125969    -0.637209        -0.631929    -0.374362        -0.374432   \n",
              "125970    -0.637209        -0.631929    -0.374362        -0.374432   \n",
              "125971     1.602664         1.605104    -0.374362        -0.374432   \n",
              "125972    -0.637209        -0.631929    -0.374362        -0.374432   \n",
              "\n",
              "        same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
              "0            0.771283      -0.349683           -0.374560       -0.324063   \n",
              "1           -1.321428       0.482201           -0.374560        0.734343   \n",
              "2           -1.389669       0.038529           -0.374560        0.734343   \n",
              "3            0.771283      -0.349683           -0.374560       -1.533670   \n",
              "4            0.771283      -0.349683           -0.028179        0.734343   \n",
              "...               ...            ...                 ...             ...   \n",
              "125968      -1.184947      -0.016930           -0.374560        0.734343   \n",
              "125969       0.771283      -0.349683           -0.374560        0.734343   \n",
              "125970       0.771283      -0.349683           -0.374560        0.734343   \n",
              "125971      -1.366922      -0.072389           -0.374560        0.734343   \n",
              "125972       0.771283      -0.349683           -0.374560        0.734343   \n",
              "\n",
              "        dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
              "0                -0.818890               -0.782367               -0.280282   \n",
              "1                -1.035688               -1.161030                2.736852   \n",
              "2                -0.809857               -0.938287               -0.174417   \n",
              "3                 1.258754                1.066401               -0.439078   \n",
              "4                 1.258754                1.066401               -0.439078   \n",
              "...                    ...                     ...                     ...   \n",
              "125968           -0.818890               -0.938287               -0.121485   \n",
              "125969            1.159389                0.977304               -0.386146   \n",
              "125970           -0.773724               -0.893738               -0.121485   \n",
              "125971           -0.972455               -1.094207               -0.174417   \n",
              "125972           -0.349162               -0.492801               -0.280282   \n",
              "\n",
              "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
              "0                          0.069972                    -0.289103   \n",
              "1                          2.367737                    -0.289103   \n",
              "2                         -0.480197                    -0.289103   \n",
              "3                         -0.383108                     0.066252   \n",
              "4                         -0.480197                    -0.289103   \n",
              "...                             ...                          ...   \n",
              "125968                    -0.480197                    -0.289103   \n",
              "125969                    -0.447834                    -0.289103   \n",
              "125970                    -0.480197                    -0.289103   \n",
              "125971                    -0.480197                    -0.289103   \n",
              "125972                     0.490690                    -0.289103   \n",
              "\n",
              "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
              "0                  -0.639532                 -0.624871             -0.224532   \n",
              "1                  -0.639532                 -0.624871             -0.387635   \n",
              "2                   1.608759                  1.618955             -0.387635   \n",
              "3                  -0.572083                 -0.602433             -0.387635   \n",
              "4                  -0.639532                 -0.624871             -0.387635   \n",
              "...                      ...                       ...                   ...   \n",
              "125968              1.608759                  1.618955             -0.387635   \n",
              "125969             -0.639532                 -0.624871             -0.387635   \n",
              "125970              0.979238                 -0.624871             -0.355014   \n",
              "125971              1.608759                  1.618955             -0.387635   \n",
              "125972             -0.639532                 -0.624871             -0.387635   \n",
              "\n",
              "        dst_host_srv_rerror_rate  protocol_type  service  flag  \n",
              "0                      -0.376387              1       20     9  \n",
              "1                      -0.376387              2       44     9  \n",
              "2                      -0.376387              1       49     5  \n",
              "3                      -0.345084              1       24     9  \n",
              "4                      -0.376387              1       24     9  \n",
              "...                          ...            ...      ...   ...  \n",
              "125968                 -0.376387              1       49     5  \n",
              "125969                 -0.376387              2       49     9  \n",
              "125970                 -0.376387              1       54     9  \n",
              "125971                 -0.376387              1       30     5  \n",
              "125972                 -0.376387              1       20     9  \n",
              "\n",
              "[125973 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82eff8ea-d130-4038-9988-4379abd226c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007679</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>-0.809262</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.717045</td>\n",
              "      <td>-0.354343</td>\n",
              "      <td>-0.637209</td>\n",
              "      <td>-0.631929</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>-0.349683</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>-0.324063</td>\n",
              "      <td>-0.818890</td>\n",
              "      <td>-0.782367</td>\n",
              "      <td>-0.280282</td>\n",
              "      <td>0.069972</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>-0.639532</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.224532</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007737</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>-0.809262</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.620982</td>\n",
              "      <td>-0.368110</td>\n",
              "      <td>-0.637209</td>\n",
              "      <td>-0.631929</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>-1.321428</td>\n",
              "      <td>0.482201</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>-1.035688</td>\n",
              "      <td>-1.161030</td>\n",
              "      <td>2.736852</td>\n",
              "      <td>2.367737</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>-0.639532</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007762</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>-0.809262</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>0.339648</td>\n",
              "      <td>-0.299273</td>\n",
              "      <td>1.602664</td>\n",
              "      <td>1.605104</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>-1.389669</td>\n",
              "      <td>0.038529</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>-0.809857</td>\n",
              "      <td>-0.938287</td>\n",
              "      <td>-0.174417</td>\n",
              "      <td>-0.480197</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>1.608759</td>\n",
              "      <td>1.618955</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007723</td>\n",
              "      <td>-0.002891</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>1.235694</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.690846</td>\n",
              "      <td>-0.313041</td>\n",
              "      <td>-0.189235</td>\n",
              "      <td>-0.184522</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>-0.349683</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>-1.533670</td>\n",
              "      <td>1.258754</td>\n",
              "      <td>1.066401</td>\n",
              "      <td>-0.439078</td>\n",
              "      <td>-0.383108</td>\n",
              "      <td>0.066252</td>\n",
              "      <td>-0.572083</td>\n",
              "      <td>-0.602433</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.345084</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007728</td>\n",
              "      <td>-0.004814</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>1.235694</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.472521</td>\n",
              "      <td>0.058678</td>\n",
              "      <td>-0.637209</td>\n",
              "      <td>-0.631929</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>-0.349683</td>\n",
              "      <td>-0.028179</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>1.258754</td>\n",
              "      <td>1.066401</td>\n",
              "      <td>-0.439078</td>\n",
              "      <td>-0.480197</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>-0.639532</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125968</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007762</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>-0.809262</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>0.872361</td>\n",
              "      <td>-0.037694</td>\n",
              "      <td>1.602664</td>\n",
              "      <td>1.605104</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>-1.184947</td>\n",
              "      <td>-0.016930</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>-0.818890</td>\n",
              "      <td>-0.938287</td>\n",
              "      <td>-0.121485</td>\n",
              "      <td>-0.480197</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>1.608759</td>\n",
              "      <td>1.618955</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125969</th>\n",
              "      <td>-0.107178</td>\n",
              "      <td>-0.007744</td>\n",
              "      <td>-0.004883</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>-0.809262</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.717045</td>\n",
              "      <td>-0.354343</td>\n",
              "      <td>-0.637209</td>\n",
              "      <td>-0.631929</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>-0.349683</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>1.159389</td>\n",
              "      <td>0.977304</td>\n",
              "      <td>-0.386146</td>\n",
              "      <td>-0.447834</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>-0.639532</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125970</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007382</td>\n",
              "      <td>-0.004823</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>1.235694</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.725778</td>\n",
              "      <td>-0.368110</td>\n",
              "      <td>-0.637209</td>\n",
              "      <td>-0.631929</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>-0.349683</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>-0.773724</td>\n",
              "      <td>-0.893738</td>\n",
              "      <td>-0.121485</td>\n",
              "      <td>-0.480197</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>0.979238</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.355014</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125971</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007762</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>-0.809262</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>0.523041</td>\n",
              "      <td>-0.271739</td>\n",
              "      <td>1.602664</td>\n",
              "      <td>1.605104</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>-1.366922</td>\n",
              "      <td>-0.072389</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>-0.972455</td>\n",
              "      <td>-1.094207</td>\n",
              "      <td>-0.174417</td>\n",
              "      <td>-0.480197</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>1.608759</td>\n",
              "      <td>1.618955</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125972</th>\n",
              "      <td>-0.110249</td>\n",
              "      <td>-0.007737</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>-0.014089</td>\n",
              "      <td>-0.089486</td>\n",
              "      <td>-0.007736</td>\n",
              "      <td>-0.095076</td>\n",
              "      <td>-0.027023</td>\n",
              "      <td>1.235694</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>-0.036652</td>\n",
              "      <td>-0.024437</td>\n",
              "      <td>-0.012385</td>\n",
              "      <td>-0.02618</td>\n",
              "      <td>-0.01861</td>\n",
              "      <td>-0.041221</td>\n",
              "      <td>-0.002817</td>\n",
              "      <td>-0.097531</td>\n",
              "      <td>-0.725778</td>\n",
              "      <td>-0.368110</td>\n",
              "      <td>-0.637209</td>\n",
              "      <td>-0.631929</td>\n",
              "      <td>-0.374362</td>\n",
              "      <td>-0.374432</td>\n",
              "      <td>0.771283</td>\n",
              "      <td>-0.349683</td>\n",
              "      <td>-0.374560</td>\n",
              "      <td>0.734343</td>\n",
              "      <td>-0.349162</td>\n",
              "      <td>-0.492801</td>\n",
              "      <td>-0.280282</td>\n",
              "      <td>0.490690</td>\n",
              "      <td>-0.289103</td>\n",
              "      <td>-0.639532</td>\n",
              "      <td>-0.624871</td>\n",
              "      <td>-0.387635</td>\n",
              "      <td>-0.376387</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125973 rows × 40 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82eff8ea-d130-4038-9988-4379abd226c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82eff8ea-d130-4038-9988-4379abd226c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82eff8ea-d130-4038-9988-4379abd226c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y=train.attack_class\n",
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8QIcY8ipdKw",
        "outputId": "644619d9-a4d0-40fa-c127-65b6483c8ee6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Normal\n",
              "1         Normal\n",
              "2            DoS\n",
              "3         Normal\n",
              "4         Normal\n",
              "           ...  \n",
              "125968       DoS\n",
              "125969    Normal\n",
              "125970    Normal\n",
              "125971       DoS\n",
              "125972    Normal\n",
              "Name: attack_class, Length: 125973, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_x,train_y, test_size = 0.2, random_state = 0)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6OWlLMJppz1",
        "outputId": "b31c693d-68bd-4e00-c56d-60849c6b5c9f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100778, 40), (25195, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "sel = RFE(RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1), n_features_to_select = 15)\n",
        "sel.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "InmlbsgKp9WR",
        "outputId": "87a2ef27-55ab-493a-b540-e49f73c69be5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RFE(estimator=RandomForestClassifier(n_jobs=-1, random_state=0),\n",
              "    n_features_to_select=15)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=RandomForestClassifier(n_jobs=-1, random_state=0),\n",
              "    n_features_to_select=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=RandomForestClassifier(n_jobs=-1, random_state=0),\n",
              "    n_features_to_select=15)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sel.get_support()\n",
        "features = X_train.columns[sel.get_support()]\n",
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We9hfJ3bqLCU",
        "outputId": "88f78798-4a62-41d2-f955-70551d1f87be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['src_bytes', 'dst_bytes', 'count', 'srv_count', 'same_srv_rate',\n",
              "       'diff_srv_rate', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
              "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
              "       'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'protocol_type',\n",
              "       'service', 'flag'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir-MkxpEqpRP",
        "outputId": "1fdff2c0-8a66-42af-d231-98abd60caf4b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_rfe = sel.transform(X_train)\n",
        "X_test_rfe = sel.transform(X_test)"
      ],
      "metadata": {
        "id": "zUC-0i7GqSY9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC \n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "#logreg = LogisticRegression(random_state=16)\n",
        "classifier = SVC(random_state=0)\n",
        "classifier.fit(X_train_rfe, y_train)\n",
        "logreg = LogisticRegression(n_jobs=-1,random_state=0)\n",
        "# fit the model with data\n",
        "logreg.fit(X_train_rfe, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "c5HMRJtbqgI1",
        "outputId": "14c16ed0-a5b6-47c2-c28d-3e665ef37291"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(n_jobs=-1, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(n_jobs=-1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=-1, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "models = []\n",
        "models.append(('SVM Classifier', classifier))\n",
        "models.append(('LogisticRegression', logreg))\n",
        "\n",
        "for i, v in models:\n",
        "    #scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
        "    accuracy = metrics.accuracy_score(y_train, v.predict(X_train_rfe))\n",
        "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train_rfe))\n",
        "    classification = metrics.classification_report(y_train, v.predict(X_train_rfe))\n",
        "    print()\n",
        "    print('============================== {} Model Evaluation =============================='.format(i))\n",
        "    print()\n",
        "    #print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
        "    #print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    \n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mguz0yRvrhZv",
        "outputId": "f7d9dcae-05e6-4037-b1be-7c6c5efceb3e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================== SVM Classifier Model Evaluation ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.955684772470182\n",
            "\n",
            "Confusion matrix:\n",
            " [[34879  1552   330     0     0]\n",
            " [  213 53285   388     0     0]\n",
            " [  193   973  8148     0     0]\n",
            " [   36   742     2     0     0]\n",
            " [    1    36     0     0     0]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.99      0.95      0.97     36761\n",
            "      Normal       0.94      0.99      0.96     53886\n",
            "       Probe       0.92      0.87      0.90      9314\n",
            "         R2L       0.00      0.00      0.00       780\n",
            "         U2R       0.00      0.00      0.00        37\n",
            "\n",
            "    accuracy                           0.96    100778\n",
            "   macro avg       0.57      0.56      0.57    100778\n",
            "weighted avg       0.95      0.96      0.95    100778\n",
            "\n",
            "\n",
            "\n",
            "============================== LogisticRegression Model Evaluation ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.9292802000436603\n",
            "\n",
            "Confusion matrix:\n",
            " [[34529  2120   112     0     0]\n",
            " [  620 51756  1504     6     0]\n",
            " [  166  1782  7366     0     0]\n",
            " [   10   668   102     0     0]\n",
            " [    2    19    16     0     0]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.98      0.94      0.96     36761\n",
            "      Normal       0.92      0.96      0.94     53886\n",
            "       Probe       0.81      0.79      0.80      9314\n",
            "         R2L       0.00      0.00      0.00       780\n",
            "         U2R       0.00      0.00      0.00        37\n",
            "\n",
            "    accuracy                           0.93    100778\n",
            "   macro avg       0.54      0.54      0.54    100778\n",
            "weighted avg       0.92      0.93      0.93    100778\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, v in models:\n",
        "    accuracy = metrics.accuracy_score(y_test, v.predict(X_test_rfe))\n",
        "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_test_rfe))\n",
        "    classification = metrics.classification_report(y_test, v.predict(X_test_rfe))\n",
        "    print()\n",
        "    print('============================== {} Model Test Results =============================='.format(i))\n",
        "    print()\n",
        "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
        "    print()\n",
        "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
        "    print()\n",
        "    print(\"Classification report:\" \"\\n\", classification) \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TZlz1l5sZXO",
        "outputId": "d57522d4-0db4-40b6-af4a-d420e4e87b8c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================== SVM Classifier Model Test Results ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.9547132367533241\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8718   375    73     0     0]\n",
            " [   53 13310    94     0     0]\n",
            " [   56   260  2026     0     0]\n",
            " [   11   204     0     0     0]\n",
            " [    0    15     0     0     0]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.99      0.95      0.97      9166\n",
            "      Normal       0.94      0.99      0.96     13457\n",
            "       Probe       0.92      0.87      0.89      2342\n",
            "         R2L       0.00      0.00      0.00       215\n",
            "         U2R       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.95     25195\n",
            "   macro avg       0.57      0.56      0.57     25195\n",
            "weighted avg       0.95      0.95      0.95     25195\n",
            "\n",
            "\n",
            "\n",
            "============================== LogisticRegression Model Test Results ==============================\n",
            "\n",
            "Model Accuracy:\n",
            " 0.9295098233776543\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 8641   505    20     0     0]\n",
            " [  156 12928   373     0     0]\n",
            " [   38   454  1850     0     0]\n",
            " [    4   177    34     0     0]\n",
            " [    0    13     2     0     0]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         DoS       0.98      0.94      0.96      9166\n",
            "      Normal       0.92      0.96      0.94     13457\n",
            "       Probe       0.81      0.79      0.80      2342\n",
            "         R2L       0.00      0.00      0.00       215\n",
            "         U2R       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.93     25195\n",
            "   macro avg       0.54      0.54      0.54     25195\n",
            "weighted avg       0.92      0.93      0.93     25195\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}